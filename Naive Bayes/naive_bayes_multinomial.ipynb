{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd3a4e9-5e71-4d5f-8582-c2141e186370",
   "metadata": {
    "id": "1bd3a4e9-5e71-4d5f-8582-c2141e186370"
   },
   "source": [
    "# Multinomial Na칦ve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fcb7b3-fc94-4ce9-b058-0b26a3b93f7a",
   "metadata": {
    "id": "08fcb7b3-fc94-4ce9-b058-0b26a3b93f7a"
   },
   "source": [
    "This Notebook will have you working and experimenting with the Multinomial Na칦ve Bayes classifier. Initially, you will transform the given data in csv file to count matrix, then calculate the priors. Use those priors to compute likelyhoods according to Multinomial Naive Bayes and then classify the test data. Please note that use of `sklearn` implementations is only for the final question of the assignment, for other doubts regarding libraries you can reach out to the TAs.\n",
    "\n",
    "The dataset is about `Spam SMS`. There is 1 attribute that is the `message`, and the class label which could be `spam` or `ham`. The data is present in `spam.csv`. It contains about 5-6000 samples.\n",
    "For your convinience the data is already pre-processed and loaded, but I suggest you to just take a look at the code for your own knowledge, and parts vectorization is left up to you which could be easily done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8a96d4-58f3-4360-b6ae-a02405ffdddb",
   "metadata": {
    "id": "aa8a96d4-58f3-4360-b6ae-a02405ffdddb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630170e6-57f8-4dae-b644-ab275a3f53a2",
   "metadata": {
    "id": "630170e6-57f8-4dae-b644-ab275a3f53a2",
    "tags": []
   },
   "source": [
    "## Reading text-based data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2430d4f2-e3ed-4e09-9e50-a446889d58cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2430d4f2-e3ed-4e09-9e50-a446889d58cf",
    "outputId": "4332c5cc-32fe-4efd-da0a-d8894b0df133"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file into pandas using a relative path\n",
    "\n",
    "df = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
    "df.dropna(how=\"any\", inplace=True, axis=1)\n",
    "df.columns = ['label', 'message']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fbeec1-2b88-4af3-b8c6-906936938951",
   "metadata": {
    "id": "c5fbeec1-2b88-4af3-b8c6-906936938951"
   },
   "source": [
    "## Pre-processing\n",
    "\n",
    "- Our main issue with our data is that it is all in text format (strings). The classification algorithms that we usally use need some sort of numerical feature vector in order to perform the classification task. There are actually many methods to convert a corpus to a vector format. The simplest is the bag-of-words approach, where each unique word in a text will be represented by one number.\n",
    "\n",
    "- As a first step, let's write a function that will split a message into its individual words and return a list. We'll also remove very common words, ('the', 'a', etc..). To do this we will take advantage of the NLTK library. It's pretty much the standard library in Python for processing text and has a lot of useful features. We'll only use some of the basic ones here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d736a35c-e849-4029-bee7-42a31f7d0b11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d736a35c-e849-4029-bee7-42a31f7d0b11",
    "outputId": "5326f654-9e60-4951-8477-2b54dfb0b7c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\use\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    STOPWORDS = stopwords.words('english') + ['u', '칲', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed807b40-7762-4968-b546-2f72817beed3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ed807b40-7762-4968-b546-2f72817beed3",
    "outputId": "02ee09cc-8762-4677-ad87-50465fe8202a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry wkly comp win FA Cup final tkts 21s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>dun say early hor c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go jurong point crazy Available bugis n great ...\n",
       "1   ham                              Ok lar Joking wif oni\n",
       "2  spam  Free entry wkly comp win FA Cup final tkts 21s...\n",
       "3   ham                    dun say early hor c already say\n",
       "4   ham             Nah think goes usf lives around though"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'] = df.message.apply(text_process)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad88d89f-1452-4e7a-9f9c-cb1094f890d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ad88d89f-1452-4e7a-9f9c-cb1094f890d1",
    "outputId": "31462e8c-82e6-46ab-e7fe-1b3b469f56d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar Joking wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry wkly comp win FA Cup final tkts 21s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>dun say early hor c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  Go jurong point crazy Available bugis n great ...\n",
       "1      0                              Ok lar Joking wif oni\n",
       "2      1  Free entry wkly comp win FA Cup final tkts 21s...\n",
       "3      0                    dun say early hor c already say\n",
       "4      0             Nah think goes usf lives around though"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.label.map({'ham':0, 'spam':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22eddba-546a-4e97-b013-2906e90946b7",
   "metadata": {
    "id": "f22eddba-546a-4e97-b013-2906e90946b7"
   },
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f859993a-2b29-4baf-a168-117151ed240b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f859993a-2b29-4baf-a168-117151ed240b",
    "outputId": "1c43a691-0556-4326-fe09-172c05576f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (5572,)\n",
      "y: (5572,)\n",
      "\n",
      "X_train: (4179,)\n",
      "y_train: (4179,)\n",
      "\n",
      "X_test: (1393,)\n",
      "y_test: (1393,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.message\n",
    "y = df.label\n",
    "\n",
    "print(f'X: {X.shape}')\n",
    "print(f'y: {y.shape}')\n",
    "print()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print()\n",
    "\n",
    "print(f'X_test: {X_test.shape}')\n",
    "print(f'y_test: {y_test.shape}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6deffc-0424-4cb6-85d2-eb74f97e8cdd",
   "metadata": {
    "id": "ba6deffc-0424-4cb6-85d2-eb74f97e8cdd",
    "tags": []
   },
   "source": [
    "## Helper code / Example code for Representing text as Numerical data using Sci-kit learn\n",
    "\n",
    "游늷 From the scikit-learn documentation:\n",
    "- Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length.\n",
    "- We will use CountVectorizer to \"convert text into a matrix of token counts\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1309604c-b9c1-4910-ab60-432f7e12824b",
   "metadata": {
    "id": "1309604c-b9c1-4910-ab60-432f7e12824b"
   },
   "outputs": [],
   "source": [
    "# example text for model training (SMS messages)\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'Please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fde24ff-b303-4526-899d-fb902eabc1d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fde24ff-b303-4526-899d-fb902eabc1d8",
    "outputId": "a9ec619e-c16e-4688-f1ed-d85dd17acc4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cab', 'call', 'me', 'please', 'tonight', 'you'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "simple_train = vect.fit_transform(simple_train)\n",
    "\n",
    "vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576f6e05-6e94-45a1-96cc-3e694cc971d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "576f6e05-6e94-45a1-96cc-3e694cc971d6",
    "outputId": "d566e0ad-2994-4004-a515-41edb5de0ae2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cab', 'call', 'me', 'please', 'tonight', 'you'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aef831c-50f0-4723-a04a-27af774f0542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aef831c-50f0-4723-a04a-27af774f0542",
    "outputId": "a6e5da20-9914-4ee4-aa64-04bd3ea6dc36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "simple_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa523614-ff0d-4f22-b8f2-4505e33a2460",
   "metadata": {
    "id": "aa523614-ff0d-4f22-b8f2-4505e33a2460"
   },
   "source": [
    "In this scheme, features and samples are defined as follows:\n",
    "\n",
    "- Each individual token occurrence frequency (normalized or not) is treated as a feature.\n",
    "- The vector of all the token frequencies for a given document is considered a multivariate sample.\n",
    "\n",
    "A corpus of documents can thus be represented by a matrix with one row per document and one column per token (e.g. word) occurring in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0a1561-6e5c-495e-b056-fc9fe376121d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "5d0a1561-6e5c-495e-b056-fc9fe376121d",
    "outputId": "2321fa9f-01c8-4d33-e5c6-658fac8f2a9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_train.toarray(), columns=vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02042133-9bad-4aa3-b0be-a53158e7102e",
   "metadata": {
    "id": "02042133-9bad-4aa3-b0be-a53158e7102e"
   },
   "source": [
    "### Transform Testing data into a document-term matrix (using existing / training vocabulary)\n",
    "\n",
    "- You are supposed to use the training vocabolary to make the count matrix for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a50c164-91ac-4861-993d-e14a2be7c6aa",
   "metadata": {
    "id": "1a50c164-91ac-4861-993d-e14a2be7c6aa"
   },
   "outputs": [],
   "source": [
    "simple_test = [\"please don't call me\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30e0b5eb-d7ab-468a-86e2-89dcd0fa0184",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30e0b5eb-d7ab-468a-86e2-89dcd0fa0184",
    "outputId": "0efbd037-8881-4783-fb53-b99441c6444c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9df0574c-6088-4418-92b4-d6d69c9d9d41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "9df0574c-6088-4418-92b4-d6d69c9d9d41",
    "outputId": "250a73d8-a182-4b3d-8833-d12e8a835981"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45268a-bc57-4a34-b496-b30751119403",
   "metadata": {
    "id": "ec45268a-bc57-4a34-b496-b30751119403"
   },
   "source": [
    "## Multinomial Naive Bayes Implementation\n",
    "\n",
    "- This task implements Mutlinomial Naive Bayes from scratch, we have used numpy to vectorize your code and matplotlib  to show your analysis.\n",
    "- Below some information has given from the documentation about Multinomial Naive Bayes, this will give you some idea about using *Smoothing Priors*.\n",
    "- There is a sub-question for experimenting with $\\alpha > 0$, you don't have to implement it separetely, try to incomporate it in same Model Class / Function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c9e325-5e71-4810-83c9-a2e3b5a547b2",
   "metadata": {
    "id": "d3c9e325-5e71-4810-83c9-a2e3b5a547b2"
   },
   "source": [
    "游늷 From the scikit-learn documentation:\n",
    "\n",
    "- Multinomial Naive Bayes implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice).\n",
    "\n",
    "- The distribution $\\theta_y = (\\theta_{y1}, \\theta_{y2}, \\dots, \\theta_{yn})$ is parametrized by vectors for each class $y$, where $n$ is the number of features (in text classification, the size of the vocabulary) and $\\theta_{yi}$ is the probability $P(x_i|y)$ of feature appearing in a sample belonging to class.\n",
    "\n",
    "- The parameters $\\theta_y$ is estimated by a smoothed version of maximum likelihood, i.e. relative frequency counting:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{yi} = \\frac{N_{yi} + \\alpha}{N_{y} + \\alpha n}\n",
    "$$\n",
    "\n",
    " where $N_{yi} = \\sum_{x \\in T}{x_i}$ is the number of times feature $i $ appears in a sample of class in the training set $T$, and $N_{y} = \\sum^{n}_{i=1}{N_{yi}}$ is the total count of all features for class $y$.\n",
    "\n",
    "- The smoothing priors $\\alpha \\gt 0$ accounts for features not present in the learning samples and **prevents zero probabilities** in further computations. Setting $\\alpha = 1$ is called Laplace smoothing, while $\\alpha \\lt 1$ is called Lidstone smoothing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14862c11-1b3c-4314-a64e-f98a185ce394",
   "metadata": {
    "id": "14862c11-1b3c-4314-a64e-f98a185ce394"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbcd1df-1c3d-477d-b0f6-c8c17868c797",
   "metadata": {
    "id": "0dbcd1df-1c3d-477d-b0f6-c8c17868c797"
   },
   "source": [
    "## Vectorizing Training Sample\n",
    "\n",
    "- Use the Helper code above to vectorize for training samples\n",
    "- Don't overthink it, its very easy to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2561b73-fc1b-47aa-8ae9-6d1ba8ad3015",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2561b73-fc1b-47aa-8ae9-6d1ba8ad3015",
    "outputId": "09c73440-8f6b-4c60-90a0-f29dada93576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['008704050406', '0121', '01223585236', ..., '칱칦harry', '칱',\n",
       "       '칱칩well'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "X_train = vect.fit_transform(X_train)\n",
    "\n",
    "vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4xY4phXLcCq1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xY4phXLcCq1",
    "outputId": "0b670820-35ff-4f9d-f60b-5ba529a5d70d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4179, 7996)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.toarray()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "V3-pDtuhcCtZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "V3-pDtuhcCtZ",
    "outputId": "a4a03d05-0073-4e26-bec5-c63a16c56f8f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>020603</th>\n",
       "      <th>02070836089</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>02073162414</th>\n",
       "      <th>02085076972</th>\n",
       "      <th>...</th>\n",
       "      <th>친쑐ts</th>\n",
       "      <th>친칪morrow</th>\n",
       "      <th>친칪rents</th>\n",
       "      <th>칣ll</th>\n",
       "      <th>칣칦</th>\n",
       "      <th>칣칦ll</th>\n",
       "      <th>칱춹ve</th>\n",
       "      <th>칱칦harry</th>\n",
       "      <th>칱</th>\n",
       "      <th>칱칩well</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4179 rows 칑 7996 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      008704050406  0121  01223585236  01223585334  0125698789  020603  \\\n",
       "0                0     0            0            0           0       0   \n",
       "1                0     0            0            0           0       0   \n",
       "2                0     0            0            0           0       0   \n",
       "3                0     0            0            0           0       0   \n",
       "4                0     0            0            0           0       0   \n",
       "...            ...   ...          ...          ...         ...     ...   \n",
       "4174             0     0            0            0           0       0   \n",
       "4175             0     0            0            0           0       0   \n",
       "4176             0     0            0            0           0       0   \n",
       "4177             0     0            0            0           0       0   \n",
       "4178             0     0            0            0           0       0   \n",
       "\n",
       "      02070836089  02072069400  02073162414  02085076972  ...  친쑐ts  \\\n",
       "0               0            0            0            0  ...      0   \n",
       "1               0            0            0            0  ...      0   \n",
       "2               0            0            0            0  ...      0   \n",
       "3               0            0            0            0  ...      0   \n",
       "4               0            0            0            0  ...      0   \n",
       "...           ...          ...          ...          ...  ...    ...   \n",
       "4174            0            0            0            0  ...      0   \n",
       "4175            0            0            0            0  ...      0   \n",
       "4176            0            0            0            0  ...      0   \n",
       "4177            0            0            0            0  ...      0   \n",
       "4178            0            0            0            0  ...      0   \n",
       "\n",
       "      친칪morrow  친칪rents  칣ll  칣칦  칣칦ll  칱춹ve  칱칦harry  칱  칱칩well  \n",
       "0            0        0    0   0     0     0        0   0       0  \n",
       "1            0        0    0   0     0     0        0   0       0  \n",
       "2            0        0    0   0     0     0        0   0       0  \n",
       "3            0        0    0   0     0     0        0   0       0  \n",
       "4            0        0    0   0     0     0        0   0       0  \n",
       "...        ...      ...  ...  ..   ...   ...      ...  ..     ...  \n",
       "4174         0        0    0   0     0     0        0   0       0  \n",
       "4175         0        0    0   0     0     0        0   0       0  \n",
       "4176         0        0    0   0     0     0        0   0       0  \n",
       "4177         0        0    0   0     0     0        0   0       0  \n",
       "4178         0        0    0   0     0     0        0   0       0  \n",
       "\n",
       "[4179 rows x 7996 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train, columns=vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec22e087-4e03-4428-8f47-4cb4f2ec1645",
   "metadata": {
    "id": "ec22e087-4e03-4428-8f47-4cb4f2ec1645"
   },
   "source": [
    "## Calculate Priors and Estimate Model's performance on Training Sample\n",
    "\n",
    "- Calculate priors based on Training Sample using your NB implementation\n",
    "- Evaluate your model's performance on Training Data ($\\alpha = 0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa85aed-f38c-4acc-9c76-339d5914118d",
   "metadata": {
    "id": "1aa85aed-f38c-4acc-9c76-339d5914118d"
   },
   "outputs": [],
   "source": [
    "d=[[0 for i in range(len(vect.vocabulary_))] for j in range(2)]\n",
    "\n",
    "feature_names = vect.get_feature_names_out()\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    if y_train.iloc[i]==0:\n",
    "        arr = np.where(X_train[i]!=0)[0]\n",
    "        for j in arr:\n",
    "            d[0][j]+=1\n",
    "    else:\n",
    "        arr = np.where(X_train[i]!=0)[0]\n",
    "        for j in arr:\n",
    "            d[1][j]+=1\n",
    "\n",
    "counts={}\n",
    "counts[0]=len(np.where(y_train==0)[0])\n",
    "counts[1]=len(np.where(y_train==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "vS8jxW8IcjUR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vS8jxW8IcjUR",
    "outputId": "2330604c-5303-4c85-f03a-61d08b164b3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4179,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha=0\n",
    "Y_pred=[]\n",
    "for i in range(len(X_train)):\n",
    "    arr= np.where(X_train[i]!=0)[0]\n",
    "    prob1 = counts[0]/(counts[0]+counts[1])\n",
    "    prob2 = counts[1]/(counts[0]+counts[1])\n",
    "    for j in arr:\n",
    "        prob1*= (d[0][j]+alpha)/(counts[0] + alpha*X_train.shape[1])\n",
    "        prob2*= (d[1][j]+alpha)/(counts[1] + alpha*X_train.shape[1])\n",
    "    if prob1>prob2:\n",
    "        Y_pred.append(0)\n",
    "    else:\n",
    "        Y_pred.append(1)\n",
    "    #print(prob1,prob2)\n",
    "Y_pred = np.asarray(Y_pred)\n",
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "C35FjHKBcjWo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C35FjHKBcjWo",
    "outputId": "6c20df5e-67bf-4b76-dd7b-693a9c267fb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data with alpha=0: 0.9932998324958124\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on train data with alpha=0: \"+str(accuracy_score(y_train,Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a6ec92-2ba4-40bf-9b5d-01825338c034",
   "metadata": {
    "id": "d8a6ec92-2ba4-40bf-9b5d-01825338c034"
   },
   "source": [
    "## Vectorizing Test Sample\n",
    "\n",
    "- Use the Training Sample vocabulary to create word count matrix for test samples\n",
    "- This is also shown in the Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cc470-b033-444f-a366-5b3213eba877",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a16cc470-b033-444f-a366-5b3213eba877",
    "outputId": "1bae3b6b-54cb-4b1d-d13f-ebf24f1eb1ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393, 7996)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vect.transform(X_test)\n",
    "X_test = X_test.toarray()\n",
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c02b84a-3116-4260-846d-50e6849efe48",
   "metadata": {
    "id": "7c02b84a-3116-4260-846d-50e6849efe48"
   },
   "source": [
    "## Estimate Model's performance on Test Sample\n",
    "\n",
    "- Evaluate your model's performance on Test Sample, using the Training Priors ($\\alpha = 0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb763cb8-5a31-4d7d-b538-b741c8cfaae8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb763cb8-5a31-4d7d-b538-b741c8cfaae8",
    "outputId": "ea63b445-0b5d-415d-a1cf-3bceb33c4ba0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha=0\n",
    "Y_pred=[]\n",
    "for i in range(len(X_test)):\n",
    "    arr= np.where(X_test[i]!=0)[0]\n",
    "    prob1 = counts[0]/(counts[0]+counts[1])\n",
    "    prob2 = counts[1]/(counts[0]+counts[1])\n",
    "    for j in arr:\n",
    "        prob1*= (d[0][j]+alpha)/(counts[0] + alpha*X_test.shape[1])\n",
    "        prob2*= (d[1][j]+alpha)/(counts[1] + alpha*X_test.shape[1])\n",
    "    if prob1>prob2:\n",
    "        Y_pred.append(0)\n",
    "    else:\n",
    "        Y_pred.append(1)\n",
    "    #print(prob1,prob2)\n",
    "Y_pred = np.asarray(Y_pred)\n",
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60UuKKyDeTBj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60UuKKyDeTBj",
    "outputId": "17a9ec76-5fd8-47c2-f7eb-63b2e02eef0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data with alpha=0: 0.9533381191672649\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test data with alpha=0: \"+str(accuracy_score(y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b415868e-4b61-4a13-abb5-22124e5312bc",
   "metadata": {
    "id": "b415868e-4b61-4a13-abb5-22124e5312bc"
   },
   "source": [
    "## Select Smoothing Priors\n",
    "\n",
    "- Refactor your code to incorporate smoothing priors, select $\\alpha = 0$ for the previous estimates / sub-questions\n",
    "- Compare the performance with different values of $\\alpha \\gt 0$ as smoothing priors to take care of zero probabilities\n",
    "- You can display a Plot or Table to show the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a707cc0d-1f16-40a5-93ec-0366165b077c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "a707cc0d-1f16-40a5-93ec-0366165b077c",
    "outputId": "ef8002dc-f000-4db6-c05a-9241412e0e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data with alpha = 0.1 : 0.9827709978463748\n",
      "Accuracy on test data with alpha = 0.2 : 0.9849246231155779\n",
      "Accuracy on test data with alpha = 0.30000000000000004 : 0.9827709978463748\n",
      "Accuracy on test data with alpha = 0.4 : 0.9820531227566404\n",
      "Accuracy on test data with alpha = 0.5 : 0.9827709978463748\n",
      "Accuracy on test data with alpha = 0.6000000000000001 : 0.9827709978463748\n",
      "Accuracy on test data with alpha = 0.7000000000000001 : 0.9820531227566404\n",
      "Accuracy on test data with alpha = 0.8 : 0.9813352476669059\n",
      "Accuracy on test data with alpha = 0.9 : 0.9798994974874372\n",
      "Best accuracy on test is: 0.9849246231155779 for alpha=: 0.2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphaArr=[]\n",
    "accArr=[]\n",
    "maxVal=0\n",
    "maxAlpha=0\n",
    "for alpha in range(1,10):\n",
    "    alpha*=0.1\n",
    "    Y_pred=[]\n",
    "    for i in range(len(X_test)):\n",
    "        arr= np.where(X_test[i]!=0)[0]\n",
    "        prob1 = np.log(counts[0]/(counts[0]+counts[1]))\n",
    "        prob2 = np.log(counts[1]/(counts[0]+counts[1]))\n",
    "        for j in arr:\n",
    "            prob1 += np.log((d[0][j]+alpha)/(counts[0] + alpha*X_test.shape[1]))\n",
    "            prob2 += np.log((d[1][j]+alpha)/(counts[1] + alpha*X_test.shape[1]))\n",
    "        if prob1>prob2:\n",
    "            Y_pred.append(0)\n",
    "        else:\n",
    "            Y_pred.append(1)\n",
    "    alphaArr.append(alpha)\n",
    "    accArr.append(accuracy_score(y_test,Y_pred))\n",
    "    print(\"Accuracy on test data with alpha = \"+str(alpha)+\" : \"+str(accuracy_score(y_test,Y_pred)))\n",
    "    if accuracy_score(y_test,Y_pred)>maxVal:\n",
    "        maxVal = accuracy_score(y_test,Y_pred)\n",
    "        maxAlpha=alpha\n",
    "print(\"Best accuracy on test is: \"+str(maxVal)+\" for alpha=: \"+str(maxAlpha))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(alphaArr, accArr, 'bo-')\n",
    "plt.xlabel('Values of alpha')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58051f8-67fb-4632-884b-23c719d4cae7",
   "metadata": {
    "id": "d58051f8-67fb-4632-884b-23c719d4cae7"
   },
   "source": [
    "## Comparison with Sci-kit Learn Implementation\n",
    "\n",
    "- Use sci-kit learn's `sklearn.naive_bayes.MultinomialNB` model to compare your implementation's performance\n",
    "- (Optional) try other classifiers from `sklearn.naive_bayes` and see if you can make them work`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a26af-2b0a-4165-9d36-b5ed774c11fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "192a26af-2b0a-4165-9d36-b5ed774c11fb",
    "outputId": "2e52a1f3-ac3f-4dbf-f0a9-752dddab5ef1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827709978463748"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test,Y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a1370b",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The Multinomial Naive Bayes classifier was effectively applied to the Spam SMS dataset, transforming text messages into numerical count vectors using the bag-of-words representation. This method models the feature counts using a multinomial distribution, which is particularly suited for discrete data such as word frequencies in text classification tasks. By computing class priors and feature likelihoods from the training data, the model classified messages as spam or ham with measurable accuracy. Incorporating smoothing priors (Laplace smoothing) improved the handling of zero-frequency features and enhanced the model뗩 performance on test data. Comparisons with the scikit-learn implementation of MultinomialNB confirmed the robustness and reliability of this approach for text-based classification problems."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai-ml-algorithms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
